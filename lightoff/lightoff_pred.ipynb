{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25uI6YyqnYXo",
        "outputId": "ed485ee5-b302-413e-8435-18e7944dee37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "!cp \"/content/gdrive/My Drive/corrected_slices_v2.zip\" .\n",
        "!unzip -qq corrected_slices_v2.zip\n",
        "!rm corrected_slices_v2.zip\n",
        "data_path = 'corrected_slices_v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyyvavG5n4Ag",
        "outputId": "59318170-6469-4363-f06b-59a2b82b3015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146\n",
            "1316\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "\n",
        "SEQUENCE_LENGTH = 600\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 5e-4\n",
        "PLOT_SAVE_DIR = 'predicted_vs_actual_plots_v2'\n",
        "\n",
        "\n",
        "def process_file(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    df['time'] = df['time'] - df['time'].iloc[0]\n",
        "    df['Coolant_temperature'] = df['Coolant_temperature'] - df['Coolant_temperature'].iloc[0]\n",
        "\n",
        "    df['Momentary Coolant change rate'] = df['Coolant_temperature'].diff().fillna(0)\n",
        "\n",
        "    features = df[['Vehicle_Speed']]\n",
        "    target = df['Momentary Coolant change rate']\n",
        "\n",
        "    features = features.iloc[:SEQUENCE_LENGTH]\n",
        "    target = target.iloc[:SEQUENCE_LENGTH]\n",
        "\n",
        "    return features.values, target.values\n",
        "\n",
        "\n",
        "\n",
        "def pad_and_normalize(data, scaler, sequence_length=SEQUENCE_LENGTH):\n",
        "    padded_data = pad_sequences(data, maxlen=sequence_length, dtype='float32', padding='post', truncating='post')\n",
        "    normalized_data = scaler.transform(padded_data.reshape(-1, padded_data.shape[-1])).reshape(padded_data.shape)\n",
        "    return normalized_data\n",
        "\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_original = []\n",
        "y_original = []\n",
        "X_augmented = []\n",
        "y_augmented = []\n",
        "\n",
        "base_folder_path = '/content/'\n",
        "\n",
        "\n",
        "folder_path = os.path.join(base_folder_path, f'corrected_slices')\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.csv'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        features, target = process_file(file_path)\n",
        "\n",
        "        # slices = filename.split('_')\n",
        "        # is_original_trip = slices[0] == slices[2] and slices[0] == slices[4]\n",
        "\n",
        "        # if is_original_trip:\n",
        "        #     X_original.append(features)\n",
        "        #     y_original.append(target)\n",
        "        # else:\n",
        "        #     X_augmented.append(features)\n",
        "        #     y_augmented.append(target)\n",
        "        X_augmented.append(features)\n",
        "        y_augmented.append(target)\n",
        "\n",
        "# Pad and convert lists to numpy arrays\n",
        "# X_original = pad_sequences(X_original, maxlen=SEQUENCE_LENGTH, dtype='float32', padding='post', truncating='post')\n",
        "# y_original = pad_sequences(y_original, maxlen=SEQUENCE_LENGTH, dtype='float32', padding='post', truncating='post')\n",
        "X_augmented = pad_sequences(X_augmented, maxlen=SEQUENCE_LENGTH, dtype='float32', padding='post', truncating='post')\n",
        "y_augmented = pad_sequences(y_augmented, maxlen=SEQUENCE_LENGTH, dtype='float32', padding='post', truncating='post')\n",
        "\n",
        "num_test = int(0.1 * len(X_augmented))\n",
        "X_test = X_augmented[:num_test]\n",
        "y_test = y_augmented[:num_test]\n",
        "X_train = X_augmented[num_test:]\n",
        "y_train = y_augmented[num_test:]\n",
        "\n",
        "scaler_X.fit(X_train.reshape(-1, X_train.shape[-1]))\n",
        "scaler_y.fit(y_train.reshape(-1, 1))\n",
        "\n",
        "joblib.dump(scaler_X, 'scaler_X_temp_added.pkl')\n",
        "joblib.dump(scaler_y, 'scaler_y_temp_added.pkl')\n",
        "\n",
        "print(len(X_test))\n",
        "print(len(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTdbn6mFrYWj",
        "outputId": "49bd964b-c358-4814-8d14-4f884d7b3e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_normalized shape: (1316, 600, 1)\n",
            "y_train_normalized shape: (1316, 600)\n",
            "X_test_normalized shape: (146, 600, 1)\n",
            "y_test_normalized shape: (146, 600)\n"
          ]
        }
      ],
      "source": [
        "X_train_normalized = pad_and_normalize(X_train, scaler_X)\n",
        "y_train_normalized = scaler_y.transform(y_train.reshape(-1, 1)).reshape(y_train.shape)\n",
        "X_test_normalized = pad_and_normalize(X_test, scaler_X)\n",
        "y_test_normalized = scaler_y.transform(y_test.reshape(-1, 1)).reshape(y_test.shape)\n",
        "\n",
        "print('X_train_normalized shape:', X_train_normalized.shape)\n",
        "print('y_train_normalized shape:', y_train_normalized.shape)\n",
        "print('X_test_normalized shape:', X_test_normalized.shape)\n",
        "print('y_test_normalized shape:', y_test_normalized.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5rPMMeZrZ-C",
        "outputId": "a3357894-13bf-4b2b-8eec-0772d9e724f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "17/17 [==============================] - 37s 1s/step - loss: 0.0080 - val_loss: 0.0033\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 20s 1s/step - loss: 0.0039 - val_loss: 0.0028\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0034 - val_loss: 0.0027\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0032 - val_loss: 0.0027\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0032 - val_loss: 0.0027\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 26s 2s/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 26s 2s/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 25s 1s/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 26s 1s/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0030 - val_loss: 0.0027\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 27s 2s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 20s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0029 - val_loss: 0.0027\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 26s 2s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 20s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 26s 2s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 20s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 25s 2s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 29s 2s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 22s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 23s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 25s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 24s 1s/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 21s 1s/step - loss: 0.0028 - val_loss: 0.0027\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7910457df100>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Bidirectional(LSTM(32, return_sequences=True, input_shape=(SEQUENCE_LENGTH, X_train_normalized.shape[-1]))),\n",
        "    Dropout(0.2),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mean_squared_error')\n",
        "\n",
        "model.fit(X_train_normalized, y_train_normalized, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FvdfGulArdFp",
        "outputId": "802625ca-7d3f-4445-91ba-d3687148f4e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('modelBLSTM_lightoff_temp_just_speed.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "maRtYFY2ri_y"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/My Drive/model_lightoff(just_speed).h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cAtfSMn-roaq",
        "outputId": "b7482160-4474-47ea-f405-ec198ebd00b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 171ms/step - loss: 0.0027\n",
            "Test Loss: 0.002730116480961442\n",
            "5/5 [==============================] - 3s 211ms/step\n"
          ]
        }
      ],
      "source": [
        "test_loss = model.evaluate(X_test_normalized, y_test_normalized)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "\n",
        "y_pred_normalized = model.predict(X_test_normalized)\n",
        "\n",
        "y_test_inv = scaler_y.inverse_transform(y_test_normalized.reshape(-1, SEQUENCE_LENGTH))\n",
        "y_pred_inv = scaler_y.inverse_transform(y_pred_normalized.reshape(-1, SEQUENCE_LENGTH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZixJzEcGrqID",
        "outputId": "2891fc78-77dd-402a-ab60-d6166386f8c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 0.09828418493270874\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
        "print(f\"Mean Squared Error: {mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Bt9XI6eR94TT",
        "outputId": "4da6ce1c-d144-4282-c396-db79ca14c798"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146\n"
          ]
        }
      ],
      "source": [
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcx1AMx1rr3D"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if not os.path.exists(PLOT_SAVE_DIR):\n",
        "    os.makedirs(PLOT_SAVE_DIR)\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    # Convert momentary to cumulative\n",
        "    cumulative_actuals = np.cumsum(y_test_inv[i], axis=0)  # assuming y_test_inv is already the inverse transformed data\n",
        "    cumulative_predictions = np.cumsum(y_pred_inv[i], axis=0)  # assuming y_pred_inv is already the inverse transformed predictions\n",
        "    # cumulative_actuals = y_test_inv[i]\n",
        "    # cumulative_predictions = y_pred_inv[i]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(cumulative_actuals, label='Actual Coolant temp')\n",
        "    plt.plot(cumulative_predictions, label='Predicted Coolant temp')\n",
        "    plt.title(f'Trip {i + 1}: Actual vs Predicted Coolant')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Coolant temp')\n",
        "    plt.legend()\n",
        "\n",
        "    plot_filename = os.path.join(PLOT_SAVE_DIR, f'trip_{i + 1}_actual_vs_predicted.png')\n",
        "    plt.savefig(plot_filename)\n",
        "    plt.close()  # Close the plot to save memory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-qak_aVrtYK"
      },
      "outputs": [],
      "source": [
        "!zip -r data_v2.zip predicted_vs_actual_plots_v2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}